---
title: "GHV - Exercises"
author: "Niels"
date: "2024-02-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rstanarm)
```

# Chapter 3 - Exercises
#### Exercise 3.1
Weighted averages: A survey is conducted in a certain city regarding support for increased
property taxes to fund schools. In this survey, higher taxes are supported by 50% of respondents
aged 18–29, 60% of respondents aged 30–44, 40% of respondents aged 45–64, and 30% of respondents aged 65 and up. Assume there is no nonresponse. Suppose the sample includes 200 respondents aged 18–29, 250 aged 30–44, 300 aged 45–64,and 250 aged 65+. Use the weighted average formula to compute the proportion of respondents in the sample who support higher taxes.
```{r - 3.1}
tot_3.1 <- 200+250+300+250
sup_taxes_3.1 <- 200/tot_3.1*0.5+250/tot_3.1*0.6+300/tot_3.1*0.4+250/tot_3.1*0.3
sup_taxes_3.1
```
So the weighted average is 44.5% that support higher taxes.

#### Exercise 3.2
Weighted averages: Continuing the previous exercise, suppose you would like to estimate the
proportion of all adults in the population who support higher taxes, so you take a weighted
average as in Section 3.1. Give a set of weights for the four age categories so that the estimated
proportion who support higher taxes for all adults in the city is 40%.
```{r - 3.2}
# I gotta make the equation: weighted average = 0.4 <=> sub_pop1/tot_pop*x1 + sub_pop2/tot_pop*x2 etc.
# If I just lock down everything except how much the young people favor it, then we only have 1 variable.
sub_taxes_3.2 <- 200/tot_3.1*0.275+250/tot_3.1*0.6+300/tot_3.1*0.4+250/tot_3.1*0.3
sub_taxes_3.2
```
Done, probably not the best way to do it, but I didn't need to go figure out how to use a solve-function.

#### Exercise 3.3 - Density functions
Probability distributions: Using R, graph probability densities for the normal distribution,
plotting several different curves corresponding to different choices of mean and standard
deviation parameters.

```{r - 3.3}
# creating distributions
set.seed(1000)
d1_3.3 <- rnorm(10000, 0, sd = 1) # 1000 samples, mean = 0, sd = 1
d2_3.3 <- rnorm(10000, 1, sd = 2) # 1000 samples, mean = 1, sd = 2
d3_3.3 <- rnorm(10000, 10, sd = 3.5) # 1000 samples, mean = 10, sd = 3.5

# combining into one dataframe with additional column for indentifying which distribution
d3.3_data <- data.frame(
  value = c(d1_3.3, d2_3.3, d3_3.3),
  distribution = factor(rep(c("A", "B", "C"), each = 10000)))

# plotting it
ggplot(d3.3_data, aes(x = value, fill = distribution)) + 
  geom_density(alpha = 0.5) + 
  labs(title = "Overlapping Density Plots of 3 Normal DIstributions",
       x = "Value", y = "Density") + 
  scale_fill_manual(values = c("red", "green", "blue"))
```

#### Exercise 3.4 - Poisson Distribution
Probability distributions: Using a bar plot in R, graph the Poisson distribution with parameter
3.5.
```{r - 3.4}
lambda_3.4 <- 3.5 # used for poisson distribution (it's called the rate)
x_values_3.4 <- 0:10

probabilities_3.4 <- dpois(x_values_3.4, lambda_3.4)

poisson_3.4 <- data.frame(value = x_values_3.4, probability = probabilities_3.4)

ggplot(poisson_3.4, aes(x = factor(value), y = probability)) + 
  geom_bar(stat = "identity", fill = "skyblue", color = "blue") + 
    labs(title = "Poisson Distribution with 3.5 Rate", 
         x = "Value",
         y = "Probability")
```

#### Exercise 3.5 - Binomial Distribution
Probability distributions: Using a bar plot in R, graph the binomial distribution with n = 20 and
p = 0.3.
```{r - 3.5}
n_3.5 <- 20
p_3.5 <- 0.3 
X_3.5 <- 0:n_3.5
binom_3.5 <- dbinom(X_3.5, n_3.5, p_3.5)

df_3.5 <- data.frame(value = X_3.5, probability = binom_3.5)

ggplot(df_3.5, aes(x = factor(value), y = probability)) + 
  geom_bar(stat = "Identity", fill = "skyblue", color = "blue") + 
  labs(title = "Binomial Distribution of Size 20 with p = 0.3",
       x = "Value",
       y = "Probability")
```
#### Exercise 3.6 - Linear Transformations (The mathy way)
Linear transformations: A test is graded from 0 to 50, with an average score of 35 and a standard deviation of 10. For comparison to other tests, it would be convenient to rescale to a mean of 100 and standard deviation of 15.
*(a) Labeling the original test scores as x and the desired rescaled test score as y, come up with a linear transformation, that is, values of a and b so that the rescaled scores y = a + bx have a mean of 100 and a standard deviation of 15.*
```{r - 3.6}
x_3.6 <- rnorm(1000, 35, sd = 10)
# So I need a way to find out the coefficients a and b that when multiplied/added with the original numbers "x" give me numbers y that get a mean on 100 and sd of 15. 

# So the equation must be:
#y_3.6 = a + b*x_3.6

# I need to do b = 1.5, because 10*1.5 = 15, then we have the standard deviation
#y_3.6 = a + 1.5*x_3.6

# Now let's find a
#m_y = a + b*m_x <=> 100 = a + 1.5*35 <=> 100 - a = 1.5*35 <=> -a = 1.5*35 - 100 = -a = -47.5 <=> a = 47.5

y_self_3.6 <- 47.5 + 1.5*x_3.6

mean(y_self_3.6)
sd(y_self_3.6)
```
Ladies and gentlemen, we got em. 


*(b) What is the range of possible values of this rescaled score y?*
The original test had the possible values between 0 to 50, thus the rescaled test must have a similar spectrum, but of course it is rescaled:
```{r - 3.6b}
y_3.6_min <- 47.5+1.5*0 #where 0 is the original grade
y_3.6_max <- 47.5+1.5*50 # where 50 is the highest possible original grade
```

*(c) Plot the line showing y vs. x.*
```{r - 3.6c}
data_3.6 <- data.frame(x_3.6, y_self_3.6)
ggplot(data_3.6, aes(x = x_3.6, y = y_self_3.6)) + 
  geom_line()
```
It is linear, so we did a good job :)

#### Exercise 3.7 - Linear Transformations (Continued)
Linear transformations: Continuing the previous exercise, there is another linear transformation that also rescales the scores to have mean 100 and standard deviation 15. What is it, and why would you not want to use it for this purpose?
```{r - 3.7}
# It is undesirable to make b negative, because it inverts the scores after the rescaling
# 100 = a - 1.5*35 <=> -a = -52.5 - 100 <=> a = 152.5
y_3.7 <- 152.5 - 1.5*x_3.6
mean(y_3.7)
sd(y_3.7)
ggplot(data_3.6, aes(x = x_3.6, y = y_3.7)) + 
  geom_line()

```

#### Exercise 3.8 - Correlated Random Variables
Correlated random variables: Suppose that the heights of husbands and wives have a correlation of 0.3, husbands’ heights have a distribution with mean 69.1 and standard deviation 2.9 inches, and wives’ heights have mean 63.7 and standard deviation 2.7 inches. Let x and y be the heights of a married couple chosen at random. What are the mean and standard deviation of the average height, (x + y)/2?
```{r - 3.8}
p_3.8 <- 0.3
mh_3.8 <- 69.1
mw_3.8 <- 63.7
sd_h_3.8 <- 2.9
sd_w_3.8 <- 2.7


```


#### Lecture 2 - Exercise Quantifying Uncertainty
```{r - l2.1}
n_l2 <- 20
sigma_l2 <- 2
mean_l2 <- 10
l2_distribution <- rnorm(n_l2, mean_l2, sigma_l2)
```

```{r - l2.1}
f_1 <- function(x){
  1/(1*sqrt(2*pi))*exp((-1/2)*((x-0)/1)^2)
}

f_2 <- function(x){
  sqrt(1/2*pi)*exp((-1*(x - 0)^2)/2)
}

f_2(-5:5)
# now I want to add a third function with parameters mu = 2 and sigma = 1
f_3 <- function(x){
  1/(1*sqrt(2*pi))*exp((-1/2)*((x-2)/1)^2)
}
# Can you make a similar plot with the ggplot2 package?
# I will try to make a similar plot with ggplot2
library(ggplot2)
x_values <- seq(-5, 5, 0.1)
data_frame <- data.frame(x_values, f_1_values, f_2_values, f_3_values)
ggplot(data = data_frame, aes(x = x_values)) + stat_function(fun = f_1, color = "blue") + stat_function(fun = f_2, color = "red") + stat_function(fun = f_3, color = "green") + 
  labs(title = "Three Normal Distributions")


# new version of function_1 with sigma = 3.0 and a new version with function_2 with sigma = 3.0. Both have a mean of 0
f_1_v2 <- function(x){
  1/(3*sqrt(2*pi))*exp((-1/2)*((x-0)/3)^2)
}

f_2_v2 <- function(x){
  sqrt(3/2*pi)*exp((-3*(x - 0)^2)/2)
}

# plot them together using ggplot
f_1_values_v2 <- f_1_v2(x_values)
f_2_values_v2 <- f_2_v2(x_values)
data_frame_v2 <- data.frame(x_values, f_1_values_v2, f_2_values_v2)
ggplot(data = data_frame_v2, aes(x = x_values)) + stat_function(fun = f_1_v2, color = "blue") + stat_function(fun = f_2_v2, color = "red") + 
  labs(title = "Two Normal Distributions with sigma = 3.0")

```

```{r - l2.2 - simulating switzerland my 7.0 and tau = 2}
n_l2.2 <- 1000000
my_l2.2 <- 7.0
sigma_l2.2 <- 1/sqrt(2)
normal_l2.2 <- rnorm(n_l2.2, my_l2.2, sigma_l2.2)

sum(normal_l2.2 > 8.4) / n_l2.2 # here we find the sum of all people above 8.4 and divide that by the total amount of people and thus we get the proportion of people who will have a score above 8.4.
```





# GHV - Chapter 4 Exercises
#### Exercise 4.1 - Comparison of Proportions
Comparison of proportions: A randomized experiment is performed within a survey. 1000
people are contacted. Half the people contacted are promised a $5 incentive to participate, and
half are not promised an incentive. The result is a 50% response rate among the treated group
and 40% response rate among the control group. Give an estimate and standard error of the
average treatment effect.
```{r - 4.1 Comparison of Proportions}
n_4.1 <- 1000
n_treated_4.1 <- n_4.1/2
n_control_4.1 <- n_4.1/2
p_treated_4.1 <- 0.5
p_control_4.1 <- 0.4

# So I can see that giving $5 to someone increases the response rate by 10%. Does this mean the effect is 10%? No, because the control group might have been more difficult to get a hold of. That is true, but how do I calculate the average treatment effect? I think I need to calculate the difference in response rates and then calculate the standard error of the difference.

r_diff <- p_treated_4.1 - p_control_4.1

se_diff <- sqrt(p_treated_4.1*(1-p_treated_4.1)/n_treated_4.1 + p_control_4.1*(1-p_control_4.1)/n_control_4.1)

se_diff
```
So the answer is 10% +/-3%

#### Exercise 4.2 - Choosing a sample size
Choosing sample size: You are designing a survey to estimate the gender gap: the difference in
support for a candidate among men and women. Assuming the respondents are a simple random
sample of the voting population, how many people do you need to poll so that the standard error
is less than 5 percentage points?
```{r - 4.2 Choosing a sample size}
#0.05 <- sqrt((0.5(1-0.5))/n_tot + 0.5(1-0.5)/n_tot)
#0.05 <- sqrt((0.5(0.5)/n_tot + (0.5(0.5))/n_tot)
#0.05 <- sqrt(0.25/n_tot + 0.25/n_tot)
#0.05 <- sqrt(2*0.25/n_tot*2)
#0.05^2 <- 2*(0.25/n_tot/2)
#0.0025 <- 2*(0.25/n_tot/2)
#0.0025*n/2 <- 2*0.25
#0.0025*n/2 <- 0.5
#0.0025*n/2*2 <- 2*0.25*2 = 1
#0.0025*n <- 1
#n <- 1/0.0025
#n <- 400
#there we go, 400 people
```

#### Exercise 4.3 - Comparison of Proportions
Comparison of proportions: You want to gather data to determine which of two students is a
better basketball shooter. One of them shoots with 30% accuracy and the other is a 40% shooter.
Each student takes 20 shots and you then compare their shooting percentages. What is the
probability that the better shooter makes more shots in this small experiment?
```{r - 4.3}
n_4.3 <- 20
p1_4.3 <- 0.3
p2_4.3 <- 0.4

# Initialize probability sum
probability_sum <- 0

# Iterate through possible successful shots by the first shooter
for (x in 0:n_4.3) {
  # Probability of the first shooter making 'x' shots
  prob_first_shooter <- dbinom(x, size = n_4.3, prob = p1_4.3)
  
  # Probability of the second shooter making more than 'x' shots
  # Since it's a discrete distribution, 'more than x' is equivalent to 'at least x+1'
  prob_second_shooter_more <- 1 - pbinom(x, size = n_4.3, prob = p2_4.3)
  
  # Add to the cumulative probability
  probability_sum <- probability_sum + (prob_first_shooter * prob_second_shooter_more)
}

# Print the result
probability_sum

## Another way to do it would be simulating it
# Parameters
n_shots <- 20
p1 <- 0.30  # Accuracy of the first shooter
p2 <- 0.40  # Accuracy of the second shooter
n_simulations <- 10000  # Number of simulations

# Simulate shots
set.seed(123)  # For reproducibility
first_shooter_results <- rbinom(n_simulations, n_shots, p1)
second_shooter_results <- rbinom(n_simulations, n_shots, p2)

# Calculate how often the second shooter scores more than the first
success_second_more <- sum(second_shooter_results > first_shooter_results) / n_simulations

# Print the probability
success_second_more
```

#### Exercise 4.4 - Designing a basketball experiment
Designing an experiment: You want to gather data to determine which of two students is a
better basketball shooter. You plan to have each student take N shots and then compare their
shooting percentages. Roughly how large does N have to be for you to have a good chance of
distinguishing a 30% shooter from a 40% shooter?
```{r - 4.4}
#0.05 <- sqrt((0.3(1-0.3))/n_tot + 0.4(1-0.4)/n_tot)
#0.05 <- sqrt(0.3(0.7)/n_tot) + 0.4(0.6)/n_total)
#0.05 <- sqrt(0.21/n_tot + 0.24/n_tot)
#0.05^2 <- 0.45/n_tot
#0.0025*n_tot <- 0.45
#n_tot <- 0.45/0.0025
n_tot <- 0.45/0.0025
n_tot
```
This is not necesarrily correct, I think it should be 10% and that I should use some packages like pwr to actually make a power calculation, but idk. 

#### Exercise 4.5 - 

